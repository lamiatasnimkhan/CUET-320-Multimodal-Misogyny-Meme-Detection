{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGl4ODmrKmLt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "#warnings.filterwarnings('ignore')\n",
        "import cv2\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import imghdr\n",
        "import re\n",
        "\n",
        "def load_images_to_dataframe(image_dir):\n",
        "    data = []\n",
        "\n",
        "    for file_name in os.listdir(image_dir):\n",
        "        file_path = os.path.join(image_dir, file_name)\n",
        "\n",
        "        # Check if it's an image file\n",
        "        if file_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.webp')):\n",
        "            try:\n",
        "                img = None  # Initialize image variable\n",
        "\n",
        "                # Try reading the image using OpenCV\n",
        "                img = cv2.imread(file_path, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "                # If OpenCV fails, try PIL\n",
        "                if img is None:\n",
        "                    print(f\"⚠️ OpenCV failed to read {file_name}, trying PIL...\")\n",
        "                    img = Image.open(file_path).convert(\"RGB\")  # Try using PIL instead\n",
        "                    img = img.resize((224, 224))\n",
        "                    img = np.array(img)\n",
        "                else:\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "                    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "                # Apply brightness/contrast adjustment\n",
        "                alpha = 1.2\n",
        "                beta = 20\n",
        "                img = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
        "\n",
        "                # Keep the full image name with extension\n",
        "                image_name = file_name  # Keep the full filename including extension (e.g., 1549.jpg)\n",
        "\n",
        "                # Append the image data and its filename to the list\n",
        "                data.append({'image_name': image_name, 'image_data': img})\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Skipping {file_name}: {e}\")\n",
        "                continue\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "    return df"
      ],
      "metadata": {
        "id": "JAqIgJEUKuQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = load_images_to_dataframe('/kaggle/input/misogyny-meme-detection/train-20250320T200243Z-001/train')\n",
        "df_test = load_images_to_dataframe('/kaggle/input/misogyny-meme-detection/test-20250327T173652Z-001/test')\n",
        "df_dev = load_images_to_dataframe('/kaggle/input/misogyny-meme-detection/dev-20250321T154338Z-001/dev')"
      ],
      "metadata": {
        "id": "nQKOfZWxKykV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train)"
      ],
      "metadata": {
        "id": "LG15IauhK2HK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_csv = pd.read_csv('/kaggle/input/misogyny-meme-detection/train.csv')\n",
        "dev_csv = pd.read_csv('/kaggle/input/misogyny-meme-detection/dev.csv')\n",
        "test_csv = pd.read_csv('/kaggle/input/misogyny-meme-detection/test.csv')\n",
        "\n",
        "train = pd.merge(train_csv, df_train, on='image_name', how='inner')\n",
        "dev = pd.merge(dev_csv, df_dev, on='image_name', how='inner')\n",
        "test = pd.merge(test_csv, df_test, on='image_name', how='inner')"
      ],
      "metadata": {
        "id": "TRsHqmKkK4ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train)"
      ],
      "metadata": {
        "id": "A3NQZ_o2K7C1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "augmented_data = []\n",
        "cnt = 0\n",
        "\n",
        "\n",
        "img_augmentations = transforms.Compose([\n",
        "    transforms.ColorJitter(brightness=0.5),\n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    transforms.RandomPosterize(bits=4),\n",
        "\n",
        "])\n",
        "\n",
        "for idx, row in train.iterrows():\n",
        "    image_data = row['image_data']\n",
        "    text = row['transcriptions']\n",
        "    label = row['labels']\n",
        "    image_name = row['image_name']\n",
        "\n",
        "    if label == 1:\n",
        "        cnt += 1\n",
        "        # print(cnt)\n",
        "\n",
        "\n",
        "        image = Image.fromarray(image_data.astype('uint8'))\n",
        "        img_aug = img_augmentations(image)\n",
        "        img_aug = np.array(img_aug)\n",
        "\n",
        "        augmented_data.append({\n",
        "            'image_data': img_aug,\n",
        "            'labels': label,\n",
        "            'image_name': image_name,\n",
        "            'transcriptions': text\n",
        "        })\n",
        "\n",
        "\n",
        "        image = Image.fromarray(image_data.astype('uint8'))\n",
        "        img_aug = img_augmentations(image)\n",
        "        img_aug = np.array(img_aug)\n",
        "\n",
        "        augmented_data.append({\n",
        "            'image_data': img_aug,\n",
        "            'labels': label,\n",
        "            'image_name': image_name,\n",
        "            'transcriptions': text\n",
        "        })\n",
        "\n",
        "\n",
        "augmented_df = pd.DataFrame(augmented_data)\n",
        "train = pd.concat([train, augmented_df], ignore_index=True)\n"
      ],
      "metadata": {
        "id": "gM-NDuRXK9m6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "60uDjJHRLB1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet"
      ],
      "metadata": {
        "id": "efcimuCSLWB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Custom Dataset class for images\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "\n",
        "        # Convert the 'Misogyny' and 'Not-Misogyny' labels to numeric (1 and 0)\n",
        "        self.df['numeric_labels'] = self.df['labels'].apply(lambda x: 1 if x == 'Misogyny' else 0)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_data = self.df.loc[idx, 'image_data']  # Image array\n",
        "        label = self.df.loc[idx, 'numeric_labels']  # Use numeric labels (0 or 1)\n",
        "\n",
        "        # Convert numpy array to PIL Image for transformation\n",
        "        image = Image.fromarray(image_data.astype('uint8'))\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, torch.tensor(label)\n",
        "\n",
        "# Image transformations (resize, normalize, and convert to tensor)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize images to 224x224 (ResNet input size)\n",
        "    transforms.ToTensor(),  # Convert image to tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ResNet normalization\n",
        "])\n",
        "\n",
        "# Assuming 'train' and 'dev' are the DataFrames for training and validation sets\n",
        "train_dataset = ImageDataset(train, transform=transform)\n",
        "dev_dataset = ImageDataset(dev, transform=transform)\n",
        "\n",
        "# Create DataLoader for batching and shuffling\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=16)\n",
        "\n",
        "# Load ResNet model\n",
        "resnet_model = models.resnet50(pretrained=True)\n",
        "num_classes = 2  # Since we have 2 classes: Misogyny (1) and Not-Misogyny (0)\n",
        "\n",
        "# Replace the final fully connected layer to match the number of classes\n",
        "resnet_model.fc = nn.Linear(resnet_model.fc.in_features, num_classes)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for binary classification\n",
        "optimizer = optim.Adam(resnet_model.parameters(), lr=1e-4)  # Adam optimizer with learning rate\n",
        "\n",
        "# Training loop\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Use GPU if available\n",
        "resnet_model.to(device)\n",
        "\n",
        "for epoch in range(30):  # Run for 30 epochs\n",
        "    resnet_model.train()  # Set model to training mode\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)  # Move images to the device (GPU or CPU)\n",
        "        labels = labels.to(device)  # Move labels to the device\n",
        "\n",
        "        optimizer.zero_grad()  # Zero out the gradients\n",
        "        outputs = resnet_model(images)  # Get model predictions\n",
        "        loss = criterion(outputs, labels)  # Calculate loss\n",
        "        loss.backward()  # Backpropagate the loss\n",
        "        optimizer.step()  # Update model weights\n",
        "        running_loss += loss.item()  # Accumulate loss\n",
        "\n",
        "    # Print the average loss for this epoch\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "# Evaluation loop\n",
        "resnet_model.eval()  # Set model to evaluation mode\n",
        "with torch.no_grad():  # No need to compute gradients during evaluation\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in dev_loader:\n",
        "        images = images.to(device)  # Move images to device\n",
        "        labels = labels.to(device)  # Move labels to device\n",
        "\n",
        "        outputs = resnet_model(images)  # Get model predictions\n",
        "        _, predicted = torch.max(outputs, 1)  # Get the class with the highest score\n",
        "        total += labels.size(0)  # Total number of samples\n",
        "        correct += (predicted == labels).sum().item()  # Correct predictions\n",
        "\n",
        "    # Calculate accuracy\n",
        "    print(f\"Accuracy: {100 * correct / total}%\")"
      ],
      "metadata": {
        "id": "9nGCeK3zLHne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, f1_score\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "resnet_model.eval()\n",
        "with torch.no_grad():\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    for batch in dev_loader:\n",
        "        # Move the batch to the device\n",
        "        images = batch[0].to(device)\n",
        "        labels = batch[1].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = resnet_model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "\n",
        "    accuracy = 100 * sum(np.array(y_true) == np.array(y_pred)) / len(y_true)\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    class_report = classification_report(y_true, y_pred)\n",
        "\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"F1-score: {f1:.4f}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(class_report)"
      ],
      "metadata": {
        "id": "Cm4LKnuBLYXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = load_images_to_dataframe('/kaggle/input/misogyny-meme-detection/test-20250327T173652Z-001/test')\n",
        "test_csv = pd.read_csv('/kaggle/input/misogyny-meme-detection/test.csv')\n",
        "test = pd.merge(test_csv, df_test, on='image_name', how='inner')\n",
        "\n",
        "# test['transcriptions'] = test['transcriptions'].apply(text_preprocessing)\n",
        "test"
      ],
      "metadata": {
        "id": "6m9QWQFfLc4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "class TestImageDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_data = self.df.loc[idx, 'image_data']\n",
        "        image = Image.fromarray(image_data.astype('uint8'))\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "# Define image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "test_dataset = TestImageDataset(test, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "\n",
        "resnet_model.eval()\n",
        "\n",
        "test_predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "\n",
        "        images = batch.to(device)\n",
        "\n",
        "\n",
        "        outputs = resnet_model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "\n",
        "        test_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "test_predictions = np.array(test_predictions)\n",
        "\n",
        "test['predictions'] = test_predictions\n",
        "\n",
        "predictions_df = pd.DataFrame({\n",
        "    'image_name': test['image_name'],\n",
        "    'predictions': test_predictions\n",
        "})\n",
        "\n",
        "predictions_df.to_csv('ResNet_Predictions.csv', index=False)\n",
        "print(\"Predictions saved\")"
      ],
      "metadata": {
        "id": "RdM-PTUsLkDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and view the CSV file\n",
        "df_loaded = pd.read_csv('/kaggle/working/ResNet_Predictions.csv')\n",
        "print(df_loaded.head())  # Display the first few rows of the CSV"
      ],
      "metadata": {
        "id": "0yp87mhbLfbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DenseNet"
      ],
      "metadata": {
        "id": "24Rvgh0xM8Yd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "import pandas as pd\n",
        "\n",
        "# Custom Dataset class for images (same as before)\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "        self.df['numeric_labels'] = self.df['labels'].apply(lambda x: 1 if x == 'Misogyny' else 0)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_data = self.df.loc[idx, 'image_data']\n",
        "        label = self.df.loc[idx, 'numeric_labels']\n",
        "        image = Image.fromarray(image_data.astype('uint8'))\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(label)\n",
        "\n",
        "# Test Dataset class (same as before)\n",
        "class TestImageDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_data = self.df.loc[idx, 'image_data']\n",
        "        image = Image.fromarray(image_data.astype('uint8'))\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "# Image transformations (same as before)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create datasets and dataloaders (same as before)\n",
        "train_dataset = ImageDataset(train, transform=transform)\n",
        "dev_dataset = ImageDataset(dev, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=16)\n",
        "\n",
        "# Load DenseNet-121 model (modified from ResNet)\n",
        "densenet_model = models.densenet121(pretrained=True)\n",
        "num_classes = 2\n",
        "\n",
        "# Replace the classifier layer (different from ResNet)\n",
        "num_features = densenet_model.classifier.in_features\n",
        "densenet_model.classifier = nn.Linear(num_features, num_classes)\n",
        "\n",
        "# Loss and optimizer (same as before)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(densenet_model.parameters(), lr=1e-4)\n",
        "\n",
        "# Training loop (same structure)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "densenet_model.to(device)\n",
        "\n",
        "for epoch in range(30):\n",
        "    densenet_model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = densenet_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "# Evaluation (same structure)\n",
        "densenet_model.eval()\n",
        "y_true, y_pred = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in dev_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = densenet_model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"F1-score: {f1:.4f}\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "# Test prediction (same structure)\n",
        "test_dataset = TestImageDataset(test, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "densenet_model.eval()\n",
        "test_predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        images = batch.to(device)\n",
        "        outputs = densenet_model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        test_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Save predictions\n",
        "predictions_df = pd.DataFrame({\n",
        "    'image_name': test['image_name'],\n",
        "    'predictions': test_predictions\n",
        "})\n",
        "predictions_df.to_csv('DenseNet_Predictions.csv', index=False)\n",
        "print(\"DenseNet predictions saved\")"
      ],
      "metadata": {
        "id": "kN8pOhRLL7hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and view the CSV file\n",
        "df_loaded = pd.read_csv('/kaggle/working/DenseNet_Predictions.csv')\n",
        "print(df_loaded.head())  # Display the first few rows of the CSV"
      ],
      "metadata": {
        "id": "2G6pLttbNJhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "InceptionV3"
      ],
      "metadata": {
        "id": "ciuUimSHNje_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "import pandas as pd\n",
        "\n",
        "# Custom Dataset class (same as before)\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "        self.df['numeric_labels'] = self.df['labels'].apply(lambda x: 1 if x == 'Misogyny' else 0)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_data = self.df.loc[idx, 'image_data']\n",
        "        label = self.df.loc[idx, 'numeric_labels']\n",
        "        image = Image.fromarray(image_data.astype('uint8'))\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(label)\n",
        "\n",
        "# Test Dataset (same as before)\n",
        "class TestImageDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_data = self.df.loc[idx, 'image_data']\n",
        "        image = Image.fromarray(image_data.astype('uint8'))\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "# InceptionV3 requires 299x299 input (different from 224x224)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((299, 299)),  # Specific to InceptionV3\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Datasets and Dataloaders (same structure)\n",
        "train_dataset = ImageDataset(train, transform=transform)\n",
        "dev_dataset = ImageDataset(dev, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=16)\n",
        "\n",
        "# Load InceptionV3 (special handling needed)\n",
        "inception_model = models.inception_v3(pretrained=True, aux_logits=False)  # Disable aux logits\n",
        "num_classes = 2\n",
        "\n",
        "# Replace last layer (different structure than ResNet/DenseNet)\n",
        "num_features = inception_model.fc.in_features\n",
        "inception_model.fc = nn.Linear(num_features, num_classes)\n",
        "\n",
        "# Loss and optimizer (same)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(inception_model.parameters(), lr=1e-4)\n",
        "\n",
        "# Training loop (modified for InceptionV3)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "inception_model.to(device)\n",
        "\n",
        "for epoch in range(30):\n",
        "    inception_model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = inception_model(images)  # No aux logits\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "# Evaluation (same structure)\n",
        "inception_model.eval()\n",
        "y_true, y_pred = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in dev_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = inception_model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"F1-score: {f1:.4f}\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "# Test prediction\n",
        "test_dataset = TestImageDataset(test, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "test_predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        images = batch.to(device)\n",
        "        outputs = inception_model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        test_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Save predictions\n",
        "predictions_df = pd.DataFrame({\n",
        "    'image_name': test['image_name'],\n",
        "    'predictions': test_predictions\n",
        "})\n",
        "predictions_df.to_csv('InceptionV3_Predictions.csv', index=False)\n",
        "print(\"InceptionV3 predictions saved\")"
      ],
      "metadata": {
        "id": "NXk-hDAQNMnk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}